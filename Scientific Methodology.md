# Scientific Methodology 

For your research, use proven methods instead of creating new ones. Choose existing simulation frameworks and experiment designs from published papers, work with established survey tools like Flow, GUESS, or QoE, and use tested interview questions for your evaluations. To validate your work, compare your results with existing data - use available test datasets and check how your findings measure up against published results. This makes your research more credible and easier to compare with other work in your field.

# Qualitative Research

While there are specific tools for heuristic evaluation, there is a vast amount of literature on qualitative research. Colleagues from game studies recommend the following book for an introduction to qualitative research. The second reference may serve as a practical entry point into the topic. 

> Dawson, C. (2019). _Introduction to research methods 5th edition: A practical guide for anyone undertaking a research project_. Robinson.

> Kaplan, B., & Maxwell, J. A. (2005). Qualitative research methods for evaluating computer information systems. In _Evaluating the organizational impact of healthcare information systems_ (pp. 30-55). New York, NY: Springer New York.

## Heuristic Evaluation

Heuristic evaluation is a method where experts use a set of guidelines, or "heuristics," to quickly identify usability issues in a system. This approach is commonly used in game engineering because it is faster and less resource-intensive than user testing, especially in the early stages of development. It helps catch design problems before more detailed testing is done.

In game research, heuristic evaluation is adapted to assess elements specific to games, like how well a system motivates and engages players. The paper below introduces a set of 28 gamification heuristics that focus on factors like player competence and autonomy, allowing designers to evaluate how effectively a game or gamified system keeps users interested

>Tondello, Gustavo F., Dennis L. Kappen, Elisa D. Mekler, Marim Ganaba, and Lennart E. Nacke. "Heuristic evaluation for gameful design." In _Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts_, pp. 315-323. 2016.

# Quantitative Research

Quantitative research involves testing a (large) group of people to gather numerical data and identify patterns or trends. The goal is to achieve statistically significant results, which help determine what works better, faster, or has a greater impact. By analyzing this data, researchers can draw conclusions about the effectiveness or success of different approaches based on measurable outcomes. 

Classical approaches in quantitative research include statistical methods such as t-tests, paired t-tests, ANOVA, and correlation testing. A t-test compares the means of two groups to see if there is a significant difference between them, while a paired t-test compares two related samples, such as measurements taken before and after an intervention. ANOVA, or Analysis of Variance, is used when comparing the means of three or more groups. Correlation testing, on the other hand, assesses the relationship between two variables to see how strongly they are associated. These methods help in determining the significance and strength of relationships or differences in the data.
## User Experience Testing
 
 User studies enable large-scale testing of player experiences, focusing on key aspects such as flow, immersion, autonomy, competence, and presence. Various established methodologies can be employed to assess these dimensions, offering reliable frameworks for research. For a master's thesis, it is advisable to select a proven and well-tested methodology and apply it to a new hypothesis. Commonly used approaches include GUESS, PXI, GEQ, and PENS, all of which provide structured ways to evaluate player experiences and are supported by extensive research. References to these methodologies are provided below.
 
> Phan, Mikki H., Joseph R. Keebler, and Barbara S. Chaparro. "The development and validation of the game user experience satisfaction scale (GUESS)." _Human factors_ 58, no. 8 (2016): 1217-1247.

> Keebler, Joseph R., William J. Shelstad, Dustin C. Smith, Barbara S. Chaparro, and Mikki H. Phan. "Validation of the GUESS-18: a short version of the Game User Experience Satisfaction Scale (GUESS)." _Journal of Usability Studies_ 16, no. 1 (2020): 49.

> Haider, Aqeel, Casper Harteveld, Daniel Johnson, Max V. Birk, Regan L. Mandryk, Magy Seif El-Nasr, Lennart E. Nacke, Kathrin Gerling, and Vero Vanden Abeele. "miniPXI: Development and validation of an eleven-item measure of the player experience inventory." _Proceedings of the ACM on Human-Computer Interaction_ 6, no. CHI PLAY (2022): 1-26.

> Abeele, Vero Vanden, Katta Spiel, Lennart Nacke, Daniel Johnson, and Kathrin Gerling. "Development and validation of the player experience inventory: A scale to measure player experiences at the level of functional and psychosocial consequences. " _International Journal of Human-Computer Studies_ 135 (2020): 102370.

| Name                                   | Constructs                                                                                           | Items | Cites | Year | Ref |
|----------------------------------------|------------------------------------------------------------------------------------------------------|-------|-------|------|-----|
| Game Engagement Questionnaire (GEQ)    | Absorption, Flow, Presence and Immersion                                                             | 19    | 1180  | 2009 | Brockmyer, Jeanne H., et al. "The development of the Game Engagement Questionnaire: A measure of engagement in video game-playing." Journal of experimental social psychology 45.4 (2009): 624-634. |
| Game Immersion Questionnaire (GIQ)     | Attraction, Time investment, Usability, Emotional attachment, Decreased perceptions, Presence and Empathy | 24    | 274   | 2015 | Cheng, M-T., H-C. She, and Leonard A. Annetta. "Game immersion experience: its hierarchical structure and impact on game-based science learning." Journal of computer assisted learning 31.3 (2015): 232-253. |
| Immersive Experience Questionnaire (IEQ) | Cognitive Involvement, Emotional Involvement, Real World Dissociation, Challenge and Control           | 31    | 2150  | 2008 | Jennett, Charlene, et al. "Measuring and defining the experience of immersion in games." International journal of human-computer studies 66.9 (2008): 641-661. |
| Player Experience of Need Satisfaction Questionnaire (PENS) | Autonomy, Competence, Relatedness, Presence and Intuitive controls                                  | 21    | 3785  | 2006 | Ryan, Richard M., C. Scott Rigby, and Andrew Przybylski. "The motivational pull of video games: A self-determination theory approach." Motivation and emotion 30 (2006): 344-360. |
| Ubisoft Perceived Experience Questionnaire (UPEQ) | Autonomy, Competence and Relatedness                                                                | 21    | 38    | 2018 | Azadvar, Ahmad, and Alessandro Canossa. "Upeq: ubisoft perceived experience questionnaire: a self-determination evaluation tool for video games." Proceedings of the 13th international conference on the foundations of digital games. 2018. |
| Player Experience Inventory (PXI)      | Ease of Control, Audiovisual Appeal, Challenge, Clarity of Goals, Progress Feedback, Meaning, Mastery, Immersion, Autonomy, Curiosity and Enjoyment | 33    | 126   | 2020 | Abeele, Vero Vanden, et al. "Development and validation of the player experience inventory: A scale to measure player experiences at the level of functional and psychosocial consequences." International Journal of Human-Computer Studies 135 (2020): 102370. |
| Game User Experience Satisfaction Scale (GUESS) | Usability/Playability, Narratives, Play Engrossment, Enjoyment, Creative Freedom, Audio Aesthetics, Personal Gratification, Social Connectivity, and Visual Aesthetics | 55    | 241   | 2016 | Phan, Mikki H., Joseph R. Keebler, and Barbara S. Chaparro. "The development and validation of the game user experience satisfaction scale (GUESS)." Human factors 58.8 (2016): 1217-1247. |
| Short Game User Experience Satisfaction Scale (GUESS-18) | Usability/Playability, Narratives, Play Engrossment, Enjoyment, Creative Freedom, Audio Aesthetics, Personal Gratification, Social Connectivity, and Visual Aesthetics | 18    | 37    | 2020 | Keebler, Joseph R., et al. "Validation of the GUESS-18: a short version of the Game User Experience Satisfaction Scale (GUESS)." Journal of Usability Studies 16.1 (2020): 49. |

## Player Types

For user experience research, it can be beneficial to analyze player types as part of your study. Several methods exist for this purpose, with the HEXAD-12 questionnaire being a popular choice due to its simplicity and brevity. This questionnaire offers a straightforward approach to identifying different player motivations, making it an efficient tool for understanding diverse player preferences. Integrating player type analysis alongside traditional user experience assessments can provide deeper insights into how different player profiles engage with the system. Additional references for methodologies are provided below.

>Tondello, G. F., Arrambide, K., Ribeiro, G., Cen, A. J. L., & Nacke, L. E. (2019). “I don’t fit into a single type”: A Trait Model and Scale of Game Playing Preferences. In _Human-Computer Interaction–INTERACT 2019: 17th IFIP TC 13 International Conference, Paphos, Cyprus, September 2–6, 2019, Proceedings, Part II 17_ (pp. 375-395). Springer International Publishing.

> Tondello, G. F., Wehbe, R. R., Diamond, L., Busch, M., Marczewski, A., & Nacke, L. E. (2016, October). The gamification user types HEXAD scale. In _Proceedings of the 2016 annual symposium on computer-human interaction in play_ (pp. 229-243).

> Krath, J., Altmeyer, M., Tondello, G. F., & Nacke, L. E. (2023, April). HEXAD-12: Developing and validating a short version of the gamification user types hexad scale. In _Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems_ (pp. 1-18).

> Mora, A., Tondello, G. F., Calvet, L., González, C., Arnedo-Moreno, J., & Nacke, L. E. (2019, June). The quest for a better tailoring of gameful design: An analysis of player type preferences. In _Proceedings of the XX international conference on human computer interaction_ (pp. 1-8).

## User Studies - Other Dimensions

Other dimensions that can be examined in user studies include aspects such as challenge and social presence. If the suggested methods do not align with your project, consider using Google Scholar to explore alternative approaches and discover new methodologies.

> De Kort, Y. A., IJsselsteijn, W. A., & Poels, K. (2007). Digital games as social presence technology: Development of the Social Presence in Gaming Questionnaire (SPGQ). _Proceedings of PRESENCE_, _195203_, 1-9.

> Denisova, A., Cairns, P., Guckelsberger, C., & Zendle, D. (2020). Measuring perceived challenge in digital games: Development & validation of the challenge originating from recent gameplay interaction scale (CORGIS). _International Journal of Human-Computer Studies_, _137_, 102383.